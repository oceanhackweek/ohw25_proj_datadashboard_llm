{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b67088-e81c-4132-9cd5-3a7e3b7865c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.schema import Document\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0021957d-df84-4e9e-b4f0-5a75a5e3f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d04485d0-3507-43d5-b7a8-e7a99eabfded",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = 'datasets.json'\n",
    "def load_safe_desc(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Load a JSON file, dump it as indented text,\n",
    "    and escape curly braces for LangChain prompts.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Convert dict/list to formatted JSON string\n",
    "    text = json.dumps(data, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # Escape braces so LangChain doesn't treat them as variables\n",
    "    safe_text = text.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "    \n",
    "    return safe_text\n",
    "\n",
    "# Example usage\n",
    "safe_desc = load_safe_desc(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea38962-7036-448d-8bc8-b43909761269",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = f\"\"\"\n",
    " Pick the best single dataset and variable (might be several) using only the task description.\n",
    "[TASK DESCRIPTION]\n",
    "{safe_desc}\n",
    "\n",
    "[OUTPUT SCHEMA â€” return ONLY these fields in this order]\n",
    "dataset: <dataset name or \"none\">\n",
    "variable: <variable name or \"none\">\n",
    "lat,lon boundaries : <[lat_min, lat_max], [lon_min, lon_max] or \"global\">\n",
    "time range: <YYYY-MM-DD to YYYY-MM-DD or \"full available\">\n",
    "suggestions (from description only): <where this variable is available (region/coverage) if stated; else \"none\">\n",
    "\n",
    "[DECISION RULES]\n",
    "- Choose the most specific dataset & variables (can be more than one) explicitly supported by the description.\n",
    "- If region/time are missing, use \"global\" and \"full available\".\n",
    "- If no suitable match exists, set dataset and variable to \"none\".\n",
    "- Suggestions must reflect ONLY what the description states (no external inference).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3be7e61c-68ea-4406-9dfc-0d5ec5771f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_safe_desc(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Load a JSON file, dump it as indented text,\n",
    "    and escape curly braces for LangChain prompts.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Convert dict/list to formatted JSON string\n",
    "    text = json.dumps(data, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # Escape braces so LangChain doesn't treat them as variables\n",
    "    safe_text = text.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "    \n",
    "    return safe_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6275ea6-efa6-4897-a1c9-b1c04fc08451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example_of_visualizations(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves example visualizations related to the query.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The user's query about plotting.\n",
    "\n",
    "    Returns:\n",
    "    - str: The content of the most relevant example file.\n",
    "    \"\"\"\n",
    "    vector_store_hf = Chroma(\n",
    "        persist_directory=\"./chroma_db_examples\",\n",
    "        embedding_function=doc_embedder\n",
    "    )\n",
    "    # Perform a similarity search\n",
    "    results = vector_store_hf.similarity_search_with_score(query, k=1)\n",
    "\n",
    "    # Extract the most relevant document\n",
    "    doc, score = results[0]\n",
    "\n",
    "    # Construct the full path to the txt file\n",
    "    file_name = doc.metadata['source'].lstrip('./')\n",
    "    full_path = os.path.join('./', file_name)\n",
    "\n",
    "    # Read and return the content of the txt file\n",
    "    try:\n",
    "        with open(full_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            return content\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {str(e)}\")\n",
    "        return \"\"  # Return empty string if error occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4239848b-44cc-48e9-9807-77a5ad72a05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def description_reader(query):\n",
    "    json_path = 'datasets.json'\n",
    "    safe_desc = load_safe_desc(json_path)\n",
    "    llm = ChatOpenAI(\n",
    "        base_url=\"https://router.huggingface.co/v1\",\n",
    "        api_key=HF_TOKEN,\n",
    "        \n",
    "        model=\"openai/gpt-oss-20b:fireworks-ai\"  \n",
    "    )\n",
    "    \n",
    "    # Create the prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", SYSTEM_PROMPT),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "    \n",
    "    # Create the chain with output parser\n",
    "    chain_no_context = prompt | llm | StrOutputParser()\n",
    "    response = chain_no_context.invoke({\"question\": query})\n",
    "    example = get_example_of_visualizations(query)\n",
    "    final_answer = response + ' you can use this code to analyse the data/n/n: ' + example\n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecd6b737-905f-46da-a12e-2320eef9b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Literal\n",
    "from pydantic import BaseModel, Field, conint, confloat\n",
    "from langchain_core.tools import StructuredTool\n",
    "class adviserPARAM(BaseModel):\n",
    "    query: str = Field(\n",
    "        ..., description=\"User query\"\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e8f1520-aa9c-411f-8957-0ee22fa4f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adviser_tool = StructuredTool.from_function(\n",
    "    description_reader,\n",
    "    name=\"adviser_tool\",\n",
    "    description=(\n",
    "        \"Use this tool to find a suitable dataset and code example\"\n",
    "    ),\n",
    "    args_schema=adviserPARAM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "703a1f2f-585f-4010-b0b1-aa68a46f00e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 24\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# System & user prompt for the agent\u001b[39;00m\n\u001b[1;32m     17\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages(\n\u001b[1;32m     18\u001b[0m     [\n\u001b[1;32m     19\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an expert in climate data analysis, you have adviser tool, which can help you to asnwer user\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms questions about variables/datasets. If the question about data, use only information from adviser_tool\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     ]\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://router.huggingface.co/v1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHF_TOKEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenai/gpt-oss-120b:fireworks-ai\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Define the agent\u001b[39;00m\n\u001b[1;32m     31\u001b[0m agent \u001b[38;5;241m=\u001b[39m create_tool_calling_agent(\n\u001b[1;32m     32\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m     33\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m     34\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m     35\u001b[0m )\n",
      "File \u001b[0;32m/home/.pixi/envs/default/lib/python3.12/site-packages/langchain_core/load/serializable.py:130\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/home/.pixi/envs/default/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:789\u001b[0m, in \u001b[0;36mBaseChatOpenAI.validate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient(\n\u001b[1;32m    783\u001b[0m             proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy, verify\u001b[38;5;241m=\u001b[39mglobal_ssl_context\n\u001b[1;32m    784\u001b[0m         )\n\u001b[1;32m    785\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    786\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client\n\u001b[1;32m    787\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _get_default_httpx_client(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_api_base, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_timeout)\n\u001b[1;32m    788\u001b[0m     }\n\u001b[0;32m--> 789\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n",
      "File \u001b[0;32m/home/.pixi/envs/default/lib/python3.12/site-packages/openai/_client.py:130\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    128\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m     )\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "# Use your existing tools\n",
    "tools = [adviser_tool]\n",
    "HF_TOKEN = '' ### ---add your API key\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
    "doc_embedder = HuggingFaceEndpointEmbeddings(\n",
    "    model=\"Qwen/Qwen3-Embedding-8B\",\n",
    "    task=\"feature-extraction\",\n",
    "    model_kwargs={\"normalize\": True},\n",
    "    huggingfacehub_api_token = HF_TOKEN\n",
    "    \n",
    ")\n",
    "# System & user prompt for the agent\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert in climate data analysis, you have adviser tool, which can help you to asnwer user's questions about variables/datasets. If the question about data, use only information from adviser_tool\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://router.huggingface.co/v1\",\n",
    "    api_key=HF_TOKEN,\n",
    "    model=\"openai/gpt-oss-120b:fireworks-ai\"  \n",
    ")\n",
    "\n",
    "# Define the agent\n",
    "agent = create_tool_calling_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "# Create the executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b03259d1-7ee1-4216-bfab-83549d5a4d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `adviser_tool` with `{'query': 'Arctic sea surface temperature dataset'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1166/2771912424.py:11: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store_hf = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mdataset: ERA5 Atmospheric Surface Analysis\n",
      "variable: sst\n",
      "lat,lon boundaries : global\n",
      "time range: 1975-01-01 to 2024-12-31\n",
      "suggestions (from description only): global you can use this code to analyse the data/n/n: import matplotlib.pyplot as plt\n",
      "import cartopy.crs as ccrs\n",
      "import cartopy.feature as cfeature\n",
      "import numpy as np\n",
      "proj = ccrs.NorthPolarStereo(central_longitude=0)\n",
      "pc = ccrs.PlateCarree()\n",
      "\n",
      "fig = plt.figure(figsize=(8, 8))\n",
      "ax = fig.add_subplot(1, 1, 1, projection=proj)\n",
      "\n",
      "# Focus on Arctic region (north of 50Â°N)\n",
      "ax.set_extent([-180, 180, 50, 90], crs=pc)\n",
      "\n",
      "# Features\n",
      "ax.add_feature(cfeature.LAND, edgecolor='black', color='lightgray', zorder=1)\n",
      "ax.add_feature(cfeature.COASTLINE, linewidth=0.6, zorder=2)\n",
      "ax.gridlines(crs=pc, draw_labels=True, linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
      "\n",
      "# Plot SST\n",
      "im = ax.pcolormesh(da.longitude, da.latitude, da, transform=pc, shading='auto')\n",
      "\n",
      "# Colorbar\n",
      "cb = plt.colorbar(im, ax=ax, orientation='horizontal', pad=0.05, shrink=0.8)\n",
      "cb.set_label(f\"{da.attrs.get('long_name', 'Variable')} [{da.attrs.get('units', '')}]\")\n",
      "\n",
      "# Title\n",
      "plt.title(\"Arctic SST (North Polar Stereographic Projection)\")\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()\u001b[0m\u001b[32;1m\u001b[1;3mBelow is a **complete, readyâ€‘toâ€‘run Python script** that\n",
      "\n",
      "1. **Downloads** the seaâ€‘surfaceâ€‘temperature (SST) variable from the **ERA5â€‘Land/Atmospheric Surface analysis** reanalysis (the most widely used, freely available global SST product).  \n",
      "2. **Selects only the Arctic domain** (north ofâ€¯50Â°â€¯N â€“ you can change the latitude cutâ€‘off if you want a tighter â€œArctic Oceanâ€ box).  \n",
      "3. **Plots** the data on a **Northâ€‘Polarâ€‘Stereo** map with coastlines, land shading, and a colour bar.\n",
      "\n",
      "> **What you need before running the script**\n",
      "> * A Pythonâ€¯3 environment with the packages listed in the â€œRequirementsâ€ section.\n",
      "> * An account on the **Copernicus Climate Data Store (CDS)**.  \n",
      ">   â€“ Register at https://cds.climate.copernicus.eu/ if you havenâ€™t already.  \n",
      ">   â€“ Install the CDS API key (`~/.cdsapirc`) as described in the CDS documentation.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Requirements\n",
      "\n",
      "```bash\n",
      "conda create -n sst-arctic python=3.11 -y\n",
      "conda activate sst-arctic\n",
      "\n",
      "# Core scientific stack\n",
      "conda install -c conda-forge numpy xarray pandas matplotlib cartopy tqdm -y\n",
      "\n",
      "# CDS API (to download ERA5)\n",
      "pip install cdsapi\n",
      "```\n",
      "\n",
      "*If you already have these packages, you can skip the installation commands.*\n",
      "\n",
      "---\n",
      "\n",
      "## 2. The script\n",
      "\n",
      "```python\n",
      "#!/usr/bin/env python\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "\"\"\"\n",
      "Plot Arctic seaâ€‘surface temperature (SST) from ERA5.\n",
      "\"\"\"\n",
      "\n",
      "import os\n",
      "import datetime as dt\n",
      "\n",
      "import numpy as np\n",
      "import xarray as xr\n",
      "import matplotlib.pyplot as plt\n",
      "import cartopy.crs as ccrs\n",
      "import cartopy.feature as cfeature\n",
      "from tqdm import tqdm\n",
      "import cdsapi\n",
      "\n",
      "# ----------------------------------------------------------------------\n",
      "# 1ï¸âƒ£  SETTINGS â€“ adjust these to your needs\n",
      "# ----------------------------------------------------------------------\n",
      "# Time period (single month â€“ you can loop over many months/years later)\n",
      "START_DATE = \"2022-01-01\"\n",
      "END_DATE   = \"2022-01-31\"   # inclusive\n",
      "\n",
      "# Arctic latitudinal cutâ€‘off (default 50Â°â€¯N)\n",
      "LAT_MIN = 50.0\n",
      "\n",
      "# Output folder for the downloaded NetCDF file(s)\n",
      "DATA_DIR = \"era5_sst\"\n",
      "os.makedirs(DATA_DIR, exist_ok=True)\n",
      "\n",
      "# ----------------------------------------------------------------------\n",
      "# 2ï¸âƒ£  DOWNLOAD ERA5 SST (if you donâ€™t have it locally)\n",
      "# ----------------------------------------------------------------------\n",
      "def download_era5_sst(start, end, target_dir):\n",
      "    \"\"\"\n",
      "    Grab monthlyâ€‘mean SST from the ERA5â€‘Land reanalysis.\n",
      "    The ERA5 variable name for SST is 'sea_surface_temperature'.\n",
      "    \"\"\"\n",
      "    api = cdsapi.Client()\n",
      "    # ERA5 provides monthly means â€“ we request the whole period in one request.\n",
      "    # If you need higher temporal resolution (e.g., daily), change 'monthly_averaged' to\n",
      "    # 'hourly'/'daily_averaged' and adjust the request accordingly.\n",
      "    request = {\n",
      "        \"product_type\": \"monthly_averaged_reanalysis\",\n",
      "        \"variable\": \"sea_surface_temperature\",\n",
      "        \"year\": [str(y) for y in range(int(start[:4]), int(end[:4])+1)],\n",
      "        \"month\": [f\"{m:02d}\" for m in range(1,13)],\n",
      "        \"time\": \"00:00\",\n",
      "        \"format\": \"netcdf\",\n",
      "    }\n",
      "\n",
      "    outfile = os.path.join(target_dir, f\"era5_sst_{start}_{end}.nc\")\n",
      "    if os.path.isfile(outfile):\n",
      "        print(f\"âš¡ File already exists â†’ {outfile}\")\n",
      "        return outfile\n",
      "\n",
      "    print(\"â³ Downloading ERA5 SST from CDS â€¦\")\n",
      "    api.retrieve(\"reanalysis-era5-single-levels-monthly-means\", request, outfile)\n",
      "    print(f\"âœ… Download finished â†’ {outfile}\")\n",
      "    return outfile\n",
      "\n",
      "\n",
      "# ----------------------------------------------------------------------\n",
      "# 3ï¸âƒ£  LOAD data with xarray and clip to the Arctic region\n",
      "# ----------------------------------------------------------------------\n",
      "def load_and_subset(nc_path, lat_min):\n",
      "    \"\"\"\n",
      "    Open the NetCDF file, squeeze singleton dimensions,\n",
      "    and select latitudes â‰¥ lat_min.\n",
      "    \"\"\"\n",
      "    ds = xr.open_dataset(nc_path)\n",
      "    # ERA5 uses the name \"sst\" for the variable\n",
      "    da = ds[\"sst\"]\n",
      "\n",
      "    # Convert Kelvin â†’ Celsius (optional, but easier to read)\n",
      "    da = da - 273.15\n",
      "    da.attrs[\"units\"] = \"Â°C\"\n",
      "    da.attrs[\"long_name\"] = \"Sea Surface Temperature (Arctic)\"\n",
      "\n",
      "    # Subset the geographic domain\n",
      "    da_arctic = da.where(da.latitude >= lat_min, drop=True)\n",
      "\n",
      "    return da_arctic\n",
      "\n",
      "\n",
      "# ----------------------------------------------------------------------\n",
      "# 4ï¸âƒ£  PLOT\n",
      "# ----------------------------------------------------------------------\n",
      "def plot_arctic_sst(da):\n",
      "    \"\"\"\n",
      "    Plot the Arctic SST on a Northâ€‘Polarâ€‘Stereo projection.\n",
      "    \"\"\"\n",
      "    # Projection objects\n",
      "    proj = ccrs.NorthPolarStereo(central_longitude=0)\n",
      "    pc = ccrs.PlateCarree()\n",
      "\n",
      "    # Create figure\n",
      "    fig = plt.figure(figsize=(9, 9))\n",
      "    ax = fig.add_subplot(1, 1, 1, projection=proj)\n",
      "\n",
      "    # Limit the view to the Arctic (50Â°â€¯N â†’ 90Â°â€¯N)\n",
      "    ax.set_extent([-180, 180, LAT_MIN, 90], crs=pc)\n",
      "\n",
      "    # Add geographic features\n",
      "    ax.add_feature(cfeature.LAND, facecolor=\"lightgray\", edgecolor=\"black\", zorder=1)\n",
      "    ax.add_feature(cfeature.COASTLINE, linewidth=0.6, zorder=2)\n",
      "    ax.add_feature(cfeature.BORDERS, linestyle=\":\", linewidth=0.5, zorder=2)\n",
      "\n",
      "    # Plot the data â€“ use pcolormesh for speed on regular grids\n",
      "    cmap = plt.cm.coolwarm\n",
      "    im = ax.pcolormesh(\n",
      "        da.longitude,\n",
      "        da.latitude,\n",
      "        da.squeeze(),      # drop the time dim if itâ€™s length 1\n",
      "        transform=pc,\n",
      "        cmap=cmap,\n",
      "        shading=\"auto\",\n",
      "    )\n",
      "\n",
      "    # Colour bar\n",
      "    cb = plt.colorbar(im, ax=ax, orientation=\"horizontal\", pad=0.05, shrink=0.8)\n",
      "    cb.set_label(f\"{da.attrs.get('long_name', 'SST')} [{da.attrs.get('units','')}]\")\n",
      "\n",
      "    # Title with timestamp\n",
      "    if \"time\" in da.coords:\n",
      "        t_str = np.datetime_as_string(da.time.values, unit=\"D\")\n",
      "        title = f\"Arctic SST â€“ {t_str}\"\n",
      "    else:\n",
      "        title = \"Arctic SST (monthly mean)\"\n",
      "    plt.title(title, fontsize=14, weight=\"bold\")\n",
      "\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "# ----------------------------------------------------------------------\n",
      "# 5ï¸âƒ£  MAIN\n",
      "# ----------------------------------------------------------------------\n",
      "def main():\n",
      "    # 1ï¸âƒ£ download (or reuse cached file)\n",
      "    nc_file = download_era5_sst(START_DATE, END_DATE, DATA_DIR)\n",
      "\n",
      "    # 2ï¸âƒ£ load & subset\n",
      "    da_arctic = load_and_subset(nc_file, LAT_MIN)\n",
      "\n",
      "    # 3ï¸âƒ£ plot\n",
      "    plot_arctic_sst(da_arctic)\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "\n",
      "### How the script works\n",
      "\n",
      "| Step | What it does | Key functions |\n",
      "|------|--------------|---------------|\n",
      "| **Download** | Calls the **CDS API** to retrieve the monthlyâ€‘averaged SST field for the period you request. The product is stored as a NetCDF file (`era5_sst_...nc`). | `cdsapi.Client().retrieve()` |\n",
      "| **Load** | Opens the NetCDF with **xarray**, converts Kelvin â†’ Celsius (optional), and selects only latitudes â‰¥â€¯`LAT_MIN` (default 50Â°â€¯N). | `xr.open_dataset()`, `.where(..., drop=True)` |\n",
      "| **Plot** | Uses **Cartopy** to draw a *Northâ€‘Polarâ€‘Stereo* map, adds land/coastline features, and draws the SST values with `pcolormesh`. | `cartopy.crs.NorthPolarStereo`, `ax.pcolormesh()` |\n",
      "| **Display** | Shows the figure interactively (`plt.show()`). If you prefer a static file, replace `plt.show()` with `plt.savefig(\"arctic_sst.png\", dpi=300)`.|\n",
      "\n",
      "---\n",
      "\n",
      "## 3ï¸âƒ£  Customising the script\n",
      "\n",
      "| Desired change | How to do it |\n",
      "|----------------|--------------|\n",
      "| **Different time resolution** (e.g., daily or hourly) | Change the `product_type` in the CDS request to `\"reanalysis\"` and add `\"day\"`/`\"time\"` entries. You may also need to loop over days and concatenate the resulting files. |\n",
      "| **Different latitude cutâ€‘off** (e.g., 66.5Â°â€¯N for the true Arctic Circle) | Set `LAT_MIN = 66.5` near the top of the file. |\n",
      "| **Apply a mask for the Arctic Ocean only** (exclude land ice) | After loading, you can intersect with a seaâ€‘ice mask (e.g., from NSIDC) or use `cdo`/`xarray` to set landâ€‘grid points to `np.nan`. |\n",
      "| **Save the figure automatically** | Replace `plt.show()` with `plt.savefig(\"arctic_sst.png\", dpi=300, bbox_inches=\"tight\")`. |\n",
      "| **Plot a time series at a given point** | Use `da_arctic.sel(latitude=xx, longitude=yy, method=\"nearest\")` and plot the resulting 1â€‘D array. |\n",
      "\n",
      "---\n",
      "\n",
      "## 4ï¸âƒ£  Quick sanityâ€‘check\n",
      "\n",
      "If you run the script asâ€‘is, you should see a colourâ€‘shaded map of the Arctic Ocean for **Januaryâ€¯2022** (or whatever month you set). Typical SST values in the Arctic are **â€‘2â€¯Â°C to +2â€¯Â°C** in winter, and **+1â€¯Â°C to +5â€¯Â°C** in summer, depending on seaâ€‘ice cover.\n",
      "\n",
      "---\n",
      "\n",
      "### ðŸŽ‰ Thatâ€™s it!\n",
      "\n",
      "You now have a selfâ€‘contained example that:\n",
      "\n",
      "* **Downloads** a reliable global SST dataset,\n",
      "* **Extracts** the Arctic region,\n",
      "* **Visualises** it with a clear, publicationâ€‘ready map.\n",
      "\n",
      "Feel free to adapt the time range, resolution, or projection to suit your project. If you hit any snags (e.g., authentication with CDS, missing packages, or projection quirks), let me know and Iâ€™ll help troubleshoot. Happy mapping!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor.invoke({\"input\": \"Plot sst for Arctic ocean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f7e0a-af91-42a5-be47-a77c8adb47f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
